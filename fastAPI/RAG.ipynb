{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retriever Augmented Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pdf loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader('./src/dataset/mail parser.pdf')\n",
    "document = loader.load()  # load the entire pdf\n",
    "len(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.document_loaders.url.UnstructuredURLLoader at 0x25f4f92df00>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': './src/dataset/mail parser.pdf', 'page': 1}, page_content='1. Creat ing a Scenario:  You s tart by creating a new scenario, which is a workflow that \\nconnects different apps and services.  For example, email, LLMs like ChatGPT, google \\nsheets etcetera.  \\n2. Add Modules:  Add the apps and services you want to connect as modules. Each \\nmodule represents a specific action (e.g., sending an email, retrieving data) . For \\ninstance, retrieving data from emails the module would be a text parser.  \\n3. Set Triggers:  Choose a trigger module that starts the scenario when a certain event \\noccurs (e.g., a new email arrives, a file is updated).  For instance, when a new email \\narrives the email is retrieved from the inbox to parse the data in it using NLP.  \\n4. Define Actions:  Add modules that perform actions based on the trigger (e.g., send a \\nnotification, create a record in a database).  For instance, once the appropriate data is \\nretrieved from an email the data is append onto a spread sheet.  \\n5. Set Filters and Conditions:  Apply filters or conditions to control when actions should \\nbe executed.  This is especially useful when you wish to abide by a particular \\napplications rate limit. For instance, to avoid error with code 429. We add a delay \\nmodule called sleep to control the waiting time before sending a request to a specific \\nAPI e.g., Gemini or  ChatGPT.  \\n6. Test and Run:  Test the scenario to ensure it works as expected, then activate it to run \\nautomatically based on your trigger conditions.  \\nFor our specific context this is how the workflow is structured. We have two different \\nworkflows on that uses Gemini for natural language processing and another workflow that \\nsends a Post request to an application that can potentially serve Llama an open -source large \\nlanguage model.  \\nBelow is a picture showcasing a workflow that utilizes Gemini for natural language processing.  \\n \\nThe scenario has 5 modules each dependent on the previous modules output apart from email . \\nA description of what each module does is as follows;  \\n• Email  – Watch email. This module watches incoming mails  in the Inbox of the \\nconnected email. The module queries for unread emails  at specified intervals. If it finds \\nan email it marks the email as read and passes the HTML content of the email to the \\nText-parser.  This is the starting point of transforming unstructured data into structured \\ndata containing rows and columns  \\n• Text Parser  – HTML to Text. T his is a custom text parser used to convert HTML to its \\ncorresponding text. For this case the text -parser takes the body of the email  with all its \\nHTML tags  then transforms it to text  by removing the HTML tags . The text is required \\nfor easier prompting of NLP models to get information within the parsed text.  \\n')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### website loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredURLLoader\n",
    "urls = ['https://cloud.google.com/vertex-ai/generative-ai/docs/start/quickstarts/quickstart-multimodal']\n",
    "loader = UnstructuredURLLoader(urls=urls)\n",
    "url_document = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/start/quickstarts/quickstart-multimodal'}, page_content='')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_document[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the document into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# split data\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=200)\n",
    "chunks = splitter.split_documents(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Email parser workflow and description  \\nInput  \\nFor this particular workflow the input is an email straight from the inbox , the following image'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create embeddings out of the splitted documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\Desktop\\ChatBot\\venv-bot\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma  # a vector db to store embeddings\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings  # to create embeddings\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "GOOGLE_API_KEY= os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### test vector embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,\n",
       " [0.05069493129849434,\n",
       "  -0.0275444146245718,\n",
       "  -0.03001042827963829,\n",
       "  -0.02415528893470764,\n",
       "  0.014552797190845013])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = GoogleGenerativeAIEmbeddings(model='models/embedding-001')\n",
    "vector = embeddings.embed_query(\"Hello, world!\")\n",
    "len(vector), vector[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create vector embeddings then store in a vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the embeddings to entire document chucks then store in a vectorStore using chroma\n",
    "vectorStore = Chroma.from_documents(documents=chunks, embedding=GoogleGenerativeAIEmbeddings(model='models/embedding-001'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_chroma.vectorstores.Chroma at 0x167e3bfe470>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our retriever to fetch documents related to users question\n",
    "retriever = vectorStore.as_retriever(search_type='similarity', search_kwargs={'k': 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_docs = retriever.invoke(\"What is the a zapier?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'page': 1, 'source': './src/dataset/mail parser.pdf'}, page_content='notification, create a record in a database).  For instance, once the appropriate data is \\nretrieved from an email the data is append onto a spread sheet.'),\n",
       " Document(metadata={'page': 1, 'source': './src/dataset/mail parser.pdf'}, page_content='sheets etcetera.  \\n2. Add Modules:  Add the apps and services you want to connect as modules. Each \\nmodule represents a specific action (e.g., sending an email, retrieving data) . For'),\n",
       " Document(metadata={'page': 1, 'source': './src/dataset/mail parser.pdf'}, page_content='retrieved from an email the data is append onto a spread sheet.  \\n5. Set Filters and Conditions:  Apply filters or conditions to control when actions should'),\n",
       " Document(metadata={'page': 1, 'source': './src/dataset/mail parser.pdf'}, page_content='occurs (e.g., a new email arrives, a file is updated).  For instance, when a new email \\narrives the email is retrieved from the inbox to parse the data in it using NLP.'),\n",
       " Document(metadata={'page': 1, 'source': './src/dataset/mail parser.pdf'}, page_content='1. Creat ing a Scenario:  You s tart by creating a new scenario, which is a workflow that \\nconnects different apps and services.  For example, email, LLMs like ChatGPT, google \\nsheets etcetera.'),\n",
       " Document(metadata={'page': 2, 'source': './src/dataset/mail parser.pdf'}, page_content='then the information is saved in a spread sheet by using python pac kages like Pandas.  \\nThis gives more flexibility as one can setup rules if there is no product information in the email'),\n",
       " Document(metadata={'page': 1, 'source': './src/dataset/mail parser.pdf'}, page_content='5. Set Filters and Conditions:  Apply filters or conditions to control when actions should \\nbe executed.  This is especially useful when you wish to abide by a particular'),\n",
       " Document(metadata={'page': 1, 'source': './src/dataset/mail parser.pdf'}, page_content='connects different apps and services.  For example, email, LLMs like ChatGPT, google \\nsheets etcetera.  \\n2. Add Modules:  Add the apps and services you want to connect as modules. Each'),\n",
       " Document(metadata={'page': 1, 'source': './src/dataset/mail parser.pdf'}, page_content='arrives the email is retrieved from the inbox to parse the data in it using NLP.  \\n4. Define Actions:  Add modules that perform actions based on the trigger (e.g., send a'),\n",
       " Document(metadata={'page': 0, 'source': './src/dataset/mail parser.pdf'}, page_content='forms.  \\nOutput  \\nOutput is a spread sheet containing the customer email address, products inquired and date the')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Creat ing a Scenario:  You s tart by creating a new scenario, which is a workflow that \\nconnects different apps and services.  For example, email, LLMs like ChatGPT, google \\nsheets etcetera.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_docs[4].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "gemini_llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", \n",
    "                                    temprature=0, \n",
    "                                    max_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = gemini_llm.invoke(\"write me a story i can tell my crush\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Once upon a time, in a bustling city lit by starlight and glowing windows, lived a shy baker. They made the most incredible treats, pastries that tasted like whispers of summer sunsets and breads as comforting as a warm hug.  But despite their talent, the baker was too timid to share their creations with the one person they truly admired - a kind and clever artist with eyes like the summer sky.\\n\\nOne day, the baker decided to be brave. They carefully packaged their most delicate pastries – moon-shaped cookies dusted with sugar like starlight – and left them anonymously at the artist's studio.  \\n\\nThe artist, upon finding the treats, was charmed. Every day, a new gift appeared: a loaf of bread swirled with cinnamon like a painter's palette, a tart decorated with sugared violets, each one a masterpiece of flavor and design. \\n\\nIntrigued, the artist began leaving sketches in return: whimsical drawings of dancing teacups, portraits of smiling fruits, and landscapes painted with coffee and spices. A silent conversation blossomed, a language spoken through sugar and charcoal.\\n\\nFinally, the baker gathered their courage and slipped a note into their next delivery, a simple invitation to meet at their bakery. The artist, heart full of warmth and curiosity, arrived the next morning.\\n\\nAnd what happened next, well, that's a story still being written... \\n\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = (\"\"\"\n",
    "            You are AI powered chatbot designed to provide \n",
    "            information and assistance for customers based on the context\n",
    "            provided to you only. Do not make anything up.\n",
    "            Only use the context you are provided.\n",
    "            \n",
    "            context: {context} \n",
    "            Question: {input}\n",
    "            \"\"\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system', prompt_template),\n",
    "        ('human', \"{input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create execution chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(gemini_llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. **Creating a Scenario:**  You start by creating a new scenario, which is a workflow that connects different apps and services. For example, email, LLMs like ChatGPT, Google sheets, etc.\n",
      "\n",
      "2. **Set Triggers:** Choose a trigger module that starts the scenario when a certain event occurs (e.g., a new email arrives, a file is updated). For instance, when a new email.\n",
      "\n",
      "3. **Set Filters and Conditions:** Apply filters or conditions to control when actions should be executed. This is especially useful when you wish to abide by a particular.\n",
      "\n",
      "4. **Define Actions:** Add modules that perform actions based on the trigger (e.g., send a notification, create a record in a database).  For instance, once the appropriate data is.\n",
      "\n",
      "5. **Test and Run:** Test the scenario to ensure it works as expected, then activate it to run automatically based on your trigger conditions. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({'input': \"What are the steps to automate workflow in make.com?\"})\n",
    "print(response['answer'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-bot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
